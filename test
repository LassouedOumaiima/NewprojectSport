package fr.ca.cats.p1354.s3600.svcdem.service.impl;

import fr.ca.cats.p0070.s1889.logging.service.Logger;
import fr.ca.cats.p0070.s1889.logging.service.LoggerService;
import fr.ca.cats.p1354.DemandeQualificationKey;
import fr.ca.cats.p1354.DemandeQualificationValue;
import fr.ca.cats.p1354.s3600.svcdem.config.ConsumerConfig;
import fr.ca.cats.p1354.s3600.svcdem.model.DictionaryPrediction;
import fr.ca.cats.p1354.s3600.svcdem.service.ConsumerService;
import fr.ca.cats.p1354.s3600.svcdem.service.ProducerService;
import fr.ca.cats.p1354.s3600.svcdem.service.SvcdemService;
import lombok.Setter;
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.errors.WakeupException;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import java.time.Duration;
import java.time.Instant;
import java.util.Collection;
import java.util.Collections;
import java.util.concurrent.atomic.AtomicBoolean;

@Service
public class ConsumerServiceImpl implements ConsumerService {

    private static final Logger LOGGER = LoggerService.getLogger(ConsumerServiceImpl.class);

    static int nbRestart = 0 ;
    @Value("${topic}")
    String topic ;

    @Value("${pollDuration}")
    String pollDuration ;

    ConsumerConfig consumerConfig;

    ProducerService producerService ;

    SvcdemService svcdemService;

    static Consumer<DemandeQualificationKey, DemandeQualificationValue> consumerKafka;

    static DictionaryPrediction dictionary ;

    @Setter
    static AtomicBoolean isConsumerClosed =  new AtomicBoolean(false);

    @Autowired
    public ConsumerServiceImpl(SvcdemService svcdemService, ProducerService producerService, ConsumerConfig consumerConfig) {
        this.svcdemService = svcdemService;
        this.producerService = producerService ;
        this.consumerConfig = consumerConfig ;
        this.consumerKafka =  consumerConfig.consumerKafka();
    }

    public void subscribeConsumer(Consumer<DemandeQualificationKey, DemandeQualificationValue> consumerKafka) {
        this.consumerKafka = consumerKafka;
        if(isConsumerClosed.get()){
            isConsumerClosed.set(false);
        }
        consumerKafka.subscribe(Collections.singletonList(topic), new ConsumerRebalanceListener() {
            @Override
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                try {
                    LOGGER.info("\n*** Partitions revoked, committing current offsets");
                    if (!isConsumerClosed.get()) {
                        consumerKafka.commitSync();
                        LOGGER.info("\n*** Partitions revoked, current offset has been committed\n");
                    } else {
                        LOGGER.debug("\n*** Consumer was closed before committing");
                    }
                } catch (CommitFailedException e) {
                    restartConsumer();
                    nbRestart = nbRestart+ 1 ;
                    LOGGER.info("\n*** onPartitionsRevoked restarting consumer nbRestart :" + nbRestart);
                    LOGGER.error("\n*** Error from consumer while commiting, restarting consumer");
                }
            }

            @Override
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                try {
                    if (!isConsumerClosed.get()) {
                        for(TopicPartition topicPartition : partitions){
                            long offset =  consumerKafka.committed(topicPartition).offset();
                            consumerKafka.seek(topicPartition, offset);
                        }
                        LOGGER.info("\n*** Partitions (re)assigned: \n"+partitions.toString());
                    } else {
                        LOGGER.debug("\n*** Consumer was closed before committing");
                    }
                } catch (Exception e) {
                    LOGGER.error("\n***  Error while Partitions assigned");
                }
            }
        });
    }

    public void restartConsumer() {
        LOGGER.info("\n*** Inside restart: " +consumerKafka);
        try {
            if(!isConsumerClosed.get()){
                wakeup();
                closeConsumer();
                consumerPoll();
            } else {
                LOGGER.info("\n*** Consumer is already closed");
            }
        } catch (Exception e) {
            LOGGER.error("\n*** Failed to close consumer: " + consumerKafka + e.getMessage() + "\n");
            Thread.interrupted();
        }
    }

    public void closeConsumer() {
        if(isConsumerClosed.compareAndSet(false,true)) {
            try{
                LOGGER.info("\n*** Closing Consumer");
                consumerKafka.close();
                LOGGER.info("\n*** Consumer closed successfully" + "\n");
            } catch(Exception exception) {
                LOGGER.error("\n*** Error while closing consumer: " + exception.getMessage() + "\n");
            }
        } else {
            LOGGER.info("\n*** Consumer was already closed");
        }
    }

    public void wakeup(){
       try {
           if (!isConsumerClosed.get()) {
                consumerKafka.wakeup();
                LOGGER.info("\n*** Success wakeup");
           } else {
            LOGGER.info("\n*** Consumer was closed before wakeup");
           }
       } catch (WakeupException e) {
            LOGGER.error("\n*** Failed to wakeup: " + consumerKafka + e.getMessage() + "\n");
       }
    }
    /**
     * Cette méthode réalise une action de poll sur le topic Kafka contenant les demande de qualifications.
     * L'action de poll se traduit par un sondage du topic.
     * Le consumer interroge le topic afin de savoir s'il a des messages à consommer.
     */
    @Async("taskExecutor")
    public void consumerPoll() {
        LOGGER.info("\n*** consumer" +
                "Poll  \n");
        dictionary = svcdemService.getDictionary();
        subscribeConsumer(consumerKafka);
        try {
            while (!isConsumerClosed.get()) {
                try{
                    ConsumerRecords<DemandeQualificationKey, DemandeQualificationValue> records = consumerKafka.poll(Duration.ofMillis((Integer.parseInt(pollDuration))));
                    for (ConsumerRecord<DemandeQualificationKey, DemandeQualificationValue> record : records) {
                        DemandeQualificationValue qualificationValue = record.value() ;
                        LOGGER.info("\n*** evt=consumer kafka message|mail_id=" + qualificationValue.getMailId() + "|evt_status=success \n" );
                        Instant startEvent = Instant.now();
                        svcdemService.processDemandeQualificationData(qualificationValue, dictionary);
                        Instant endEvent = Instant.now();
                        Duration duration= Duration.between(startEvent, endEvent);
                        LOGGER.info("\n-->Duration record= "+ duration.getSeconds()+"sec "+duration.toMillis()+"ms\n");
                    }
                    consumerKafka.commitSync();
                } catch(CommitFailedException exp) {
                    LOGGER.error("\n*** Error from consumer while commiting "+ exp.getMessage() + "\n");
                    restartConsumer();
                    nbRestart = nbRestart+ 1 ;
                    LOGGER.info("\n*** restarting consumer nbRestart :" + nbRestart);
                    if(nbRestart > 5){
                        LOGGER.warn("\n*** Warning nbRestart is above 5"+ "\n");
                    }

                } catch(WakeupException ex){
                    LOGGER.error("\n*** Kafka Consumer wakeup exception "+ ex.getMessage() + "\n");
                } catch(Exception ex){
                    LOGGER.error("\n*** Error while polling from topic "+ ex.getMessage() + "\n");
                    break;
                }
            }/**End of while loop*/
        } finally {
            closeConsumer();
        }
    }


}
